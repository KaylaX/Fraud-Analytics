library(ggplot2)
library(dplyr)
library(scales)
library(knitr)
library(tidyr)
library(lubridate)
library(ggmap)
library(stringr)
library(gdata)
library(xlsx)
library(readxl)
library(RJSONIO)
#DATA CLEANING

setwd("~/Desktop/DSO 562 Fraud Analytics/Week 2")

ny_property <- read_excel("NY property 1 million.xlsx")

#1)counting missing values and unique values
#counting missing values
missing_values <- sapply(ny_property, function(x) sum(is.na(x)))
missing_values

#counting unique values
unique_values <- sapply(ny_property, function(x) length(unique(x)))
unique_values

str(ny_property)

#get rid of non-numerical fields that dont make sense 
#(not interesting for fraud, not valuable, not informatives) 
#in order to perform the data cleaning

# According to the data dictionary, BBLE, BLOCK, LOT are all unique numerical values. 
# BBLE is a combination of boro, block and lot. 

#We should delete block and lot and incorporate BORO with 5 levels 
#for better analysis.

# BORO CODES
# 1 = MANHATTAN
# 2 = BRONX
# 3 = BROOKLYN
# 4 = QUEENS
# 5 = STATEN ISLAND

#PERIOD, YEAR ,VALTYPE are not needed 
#because there is no missing values and they 
#all have the same value for each obversation
# they should all be deleted.

#STADDR are street names, missing values of street names do not mean they dont have a street, 
#it is just unknown so we would need only the ZIP code to have a geographical field. 
#We can use STADDR to look up the zipcodes that are missing.

#OWNER is not a numerical value. 
#We can only clean the name to be in specific format such as First Name and Last name
#However We do not have the power to replace the missing values of owner. 
#Because of the complexity of nicknames and fuzzy match. DELETE


#Before deleting BBLE, BLOCK, LOT. Lets add BORO
View(ny_property)
str_extract(ny_property$BBLE, "[0-9]")

#2)Creating a "BORO" column by extracting the first number from "BBLE"
ny_property <- ny_property %>%
                  mutate(BORO = str_extract(ny_property$BBLE, "[0-9]"))

dim(ny_property) #For reference index 31 column is BORO

#3)Deleting the irrelevant fields as mentioned above
#after manual counting which index is which field that needs to be deleted.

ny_property_new <- ny_property[,-c(c(2,3,4,6,18,28,29,30))]

str(ny_property_new)

#4)Replace missing values

#EASEMENT

#EASEMENT is a categorical field 
#but missing values means they are just no easement. 
#It is not a real missing value.

#EASEMENT replace all values of duplicate F through M to E

str_replace(c("M,Y"), "E", "%[A")

missing_values <- sapply(ny_property_new, function(x) sum(is.na(x)))
missing_values

#ZIP

#ZIP has 26356 missing values. 
#Replace the missing values by looking up the street address using ggmap and manual filling
#The zips that cannot be found by street address (since they are blank or incomplete) are
#replaced by the most frequent zip by BORO.

geocodeAdddress <- function(address) {
  require(RJSONIO)
  url <- "http://maps.google.com/maps/api/geocode/json?address="
  url <- URLencode(paste(url, address, "&sensor=false", sep = ""))
  x <- fromJSON(url, simplify = FALSE)
  if (x$status == "OK") {
    out <- c(x$results[[1]]$geometry$location$lng,
             x$results[[1]]$geometry$location$lat)
  } else {
    out <- NA
  }
  Sys.sleep(0.2)  # API only allows 5 requests per second
  out
}

geocodeAdddress('COYLE STREET, NEW YORK')

STADDRBORO <- read_xlsx("STADDRBORO1.xlsx")

locations  <- lapply(STADDRBORO$STADDRBORO, function(x) geocodeAdddress(x))


locations_data <- do.call(rbind.data.frame, locations)

locations_data1 <- bind_cols(STADDRBORO, locations_data)

#get zip

latlon2zip <- function(lat, lon) {
  url <- sprintf("http://nominatim.openstreetmap.org/reverse?format=json&lat=%f&lon=%f&zoom=18&addressdetails=1", lat, lon)
  res <- fromJSON(url)
  return(res[["address"]][["postcode"]])
}


lonlat_sample <- geocode(STADDRBORO$STADDRBORO)


res <- revgeocode(lonlat_sample, output="more")
res
